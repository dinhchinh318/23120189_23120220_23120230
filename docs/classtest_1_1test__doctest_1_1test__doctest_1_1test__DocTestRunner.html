<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>PHONE MANAGEMENT: test.test_doctest.test_doctest.test_DocTestRunner Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">PHONE MANAGEMENT
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>test</b></li><li class="navelem"><b>test_doctest</b></li><li class="navelem"><a class="el" href="namespacetest_1_1test__doctest_1_1test__doctest.html">test_doctest</a></li><li class="navelem"><a class="el" href="classtest_1_1test__doctest_1_1test__doctest_1_1test__DocTestRunner.html">test_DocTestRunner</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classtest_1_1test__doctest_1_1test__doctest_1_1test__DocTestRunner-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">test.test_doctest.test_doctest.test_DocTestRunner Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a333819a84b41078fd8a06d0a94710b62"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtest_1_1test__doctest_1_1test__doctest_1_1test__DocTestRunner.html#a333819a84b41078fd8a06d0a94710b62">basics</a> ()</td></tr>
<tr class="separator:a333819a84b41078fd8a06d0a94710b62"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6a1a17315e6966427dbbba5cecafa9cb"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtest_1_1test__doctest_1_1test__doctest_1_1test__DocTestRunner.html#a6a1a17315e6966427dbbba5cecafa9cb">verbose_flag</a> ()</td></tr>
<tr class="separator:a6a1a17315e6966427dbbba5cecafa9cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a27f6402477de1b2e6ff4bd8e77111267"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtest_1_1test__doctest_1_1test__doctest_1_1test__DocTestRunner.html#a27f6402477de1b2e6ff4bd8e77111267">exceptions</a> ()</td></tr>
<tr class="separator:a27f6402477de1b2e6ff4bd8e77111267"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1018ab77d7631e430c8b1357b7ce202b"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtest_1_1test__doctest_1_1test__doctest_1_1test__DocTestRunner.html#a1018ab77d7631e430c8b1357b7ce202b">displayhook</a> ()</td></tr>
<tr class="separator:a1018ab77d7631e430c8b1357b7ce202b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02b31e6aacfb7e1b5bc7083392f3d440"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtest_1_1test__doctest_1_1test__doctest_1_1test__DocTestRunner.html#a02b31e6aacfb7e1b5bc7083392f3d440">optionflags</a> ()</td></tr>
<tr class="separator:a02b31e6aacfb7e1b5bc7083392f3d440"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a73e15e4f95afc8b2f8afec2a54606128"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtest_1_1test__doctest_1_1test__doctest_1_1test__DocTestRunner.html#a73e15e4f95afc8b2f8afec2a54606128">option_directives</a> ()</td></tr>
<tr class="separator:a73e15e4f95afc8b2f8afec2a54606128"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a333819a84b41078fd8a06d0a94710b62"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a333819a84b41078fd8a06d0a94710b62">&#9670;&nbsp;</a></span>basics()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def test.test_doctest.test_doctest.test_DocTestRunner.basics </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Unit tests for the `DocTestRunner` class.

DocTestRunner is used to run DocTest test cases, and to accumulate
statistics.  Here's a simple DocTest case we can use:

&gt;&gt;&gt; def f(x):
...     '''
...     &gt;&gt;&gt; x = 12
...     &gt;&gt;&gt; print(x)
...     12
...     &gt;&gt;&gt; x//2
...     6
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]

The main DocTestRunner interface is the `run` method, which runs a
given DocTest case in a given namespace (globs).  It returns a tuple
`(f,t)`, where `f` is the number of failed tests and `t` is the number
of tried tests.

&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
TestResults(failed=0, attempted=3)

If any example produces incorrect output, then the test runner reports
the failure and proceeds to the next example:

&gt;&gt;&gt; def f(x):
...     '''
...     &gt;&gt;&gt; x = 12
...     &gt;&gt;&gt; print(x)
...     14
...     &gt;&gt;&gt; x//2
...     6
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=True).run(test)
... # doctest: +ELLIPSIS
Trying:
    x = 12
Expecting nothing
ok
Trying:
    print(x)
Expecting:
    14
**********************************************************************
File ..., line 4, in f
Failed example:
    print(x)
Expected:
    14
Got:
    12
Trying:
    x//2
Expecting:
    6
ok
TestResults(failed=1, attempted=3)
</pre> 
</div>
</div>
<a id="a1018ab77d7631e430c8b1357b7ce202b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1018ab77d7631e430c8b1357b7ce202b">&#9670;&nbsp;</a></span>displayhook()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def test.test_doctest.test_doctest.test_DocTestRunner.displayhook </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test that changing sys.displayhook doesn't matter for doctest.

&gt;&gt;&gt; import sys
&gt;&gt;&gt; orig_displayhook = sys.displayhook
&gt;&gt;&gt; def my_displayhook(x):
...     print('hi!')
&gt;&gt;&gt; sys.displayhook = my_displayhook
&gt;&gt;&gt; def f():
...     '''
...     &gt;&gt;&gt; 3
...     3
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; r = doctest.DocTestRunner(verbose=False).run(test)
&gt;&gt;&gt; post_displayhook = sys.displayhook

We need to restore sys.displayhook now, so that we'll be able to test
results.

&gt;&gt;&gt; sys.displayhook = orig_displayhook

Ok, now we can check that everything is ok.

&gt;&gt;&gt; r
TestResults(failed=0, attempted=1)
&gt;&gt;&gt; post_displayhook is my_displayhook
True
</pre> 
</div>
</div>
<a id="a27f6402477de1b2e6ff4bd8e77111267"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a27f6402477de1b2e6ff4bd8e77111267">&#9670;&nbsp;</a></span>exceptions()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def test.test_doctest.test_doctest.test_DocTestRunner.exceptions </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Tests of `DocTestRunner`'s exception handling.

An expected exception is specified with a traceback message.  The
lines between the first line and the type/value may be omitted or
replaced with any other string:

&gt;&gt;&gt; def f(x):
...     '''
...     &gt;&gt;&gt; x = 12
...     &gt;&gt;&gt; print(x//0)
...     Traceback (most recent call last):
...     ZeroDivisionError: integer division or modulo by zero
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
TestResults(failed=0, attempted=2)

An example may not generate output before it raises an exception; if
it does, then the traceback message will not be recognized as
signaling an expected exception, so the example will be reported as an
unexpected exception:

&gt;&gt;&gt; def f(x):
...     '''
...     &gt;&gt;&gt; x = 12
...     &gt;&gt;&gt; print('pre-exception output', x//0)
...     pre-exception output
...     Traceback (most recent call last):
...     ZeroDivisionError: integer division or modulo by zero
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 4, in f
Failed example:
    print('pre-exception output', x//0)
Exception raised:
    ...
    ZeroDivisionError: integer division or modulo by zero
TestResults(failed=1, attempted=2)

Exception messages may contain newlines:

&gt;&gt;&gt; def f(x):
...     r'''
...     &gt;&gt;&gt; raise ValueError('multi\nline\nmessage')
...     Traceback (most recent call last):
...     ValueError: multi
...     line
...     message
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
TestResults(failed=0, attempted=1)

If an exception is expected, but an exception with the wrong type or
message is raised, then it is reported as a failure:

&gt;&gt;&gt; def f(x):
...     r'''
...     &gt;&gt;&gt; raise ValueError('message')
...     Traceback (most recent call last):
...     ValueError: wrong message
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 3, in f
Failed example:
    raise ValueError('message')
Expected:
    Traceback (most recent call last):
    ValueError: wrong message
Got:
    Traceback (most recent call last):
    ...
    ValueError: message
TestResults(failed=1, attempted=1)

However, IGNORE_EXCEPTION_DETAIL can be used to allow a mismatch in the
detail:

&gt;&gt;&gt; def f(x):
...     r'''
...     &gt;&gt;&gt; raise ValueError('message') #doctest: +IGNORE_EXCEPTION_DETAIL
...     Traceback (most recent call last):
...     ValueError: wrong message
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
TestResults(failed=0, attempted=1)

IGNORE_EXCEPTION_DETAIL also ignores difference in exception formatting
between Python versions. For example, in Python 2.x, the module path of
the exception is not in the output, but this will fail under Python 3:

&gt;&gt;&gt; def f(x):
...     r'''
...     &gt;&gt;&gt; from http.client import HTTPException
...     &gt;&gt;&gt; raise HTTPException('message')
...     Traceback (most recent call last):
...     HTTPException: message
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 4, in f
Failed example:
    raise HTTPException('message')
Expected:
    Traceback (most recent call last):
    HTTPException: message
Got:
    Traceback (most recent call last):
    ...
    http.client.HTTPException: message
TestResults(failed=1, attempted=2)

But in Python 3 the module path is included, and therefore a test must look
like the following test to succeed in Python 3. But that test will fail under
Python 2.

&gt;&gt;&gt; def f(x):
...     r'''
...     &gt;&gt;&gt; from http.client import HTTPException
...     &gt;&gt;&gt; raise HTTPException('message')
...     Traceback (most recent call last):
...     http.client.HTTPException: message
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
TestResults(failed=0, attempted=2)

However, with IGNORE_EXCEPTION_DETAIL, the module name of the exception
(or its unexpected absence) will be ignored:

&gt;&gt;&gt; def f(x):
...     r'''
...     &gt;&gt;&gt; from http.client import HTTPException
...     &gt;&gt;&gt; raise HTTPException('message') #doctest: +IGNORE_EXCEPTION_DETAIL
...     Traceback (most recent call last):
...     HTTPException: message
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
TestResults(failed=0, attempted=2)

The module path will be completely ignored, so two different module paths will
still pass if IGNORE_EXCEPTION_DETAIL is given. This is intentional, so it can
be used when exceptions have changed module.

&gt;&gt;&gt; def f(x):
...     r'''
...     &gt;&gt;&gt; from http.client import HTTPException
...     &gt;&gt;&gt; raise HTTPException('message') #doctest: +IGNORE_EXCEPTION_DETAIL
...     Traceback (most recent call last):
...     foo.bar.HTTPException: message
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
TestResults(failed=0, attempted=2)

But IGNORE_EXCEPTION_DETAIL does not allow a mismatch in the exception type:

&gt;&gt;&gt; def f(x):
...     r'''
...     &gt;&gt;&gt; raise ValueError('message') #doctest: +IGNORE_EXCEPTION_DETAIL
...     Traceback (most recent call last):
...     TypeError: wrong type
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 3, in f
Failed example:
    raise ValueError('message') #doctest: +IGNORE_EXCEPTION_DETAIL
Expected:
    Traceback (most recent call last):
    TypeError: wrong type
Got:
    Traceback (most recent call last):
    ...
    ValueError: message
TestResults(failed=1, attempted=1)

If the exception does not have a message, you can still use
IGNORE_EXCEPTION_DETAIL to normalize the modules between Python 2 and 3:

&gt;&gt;&gt; def f(x):
...     r'''
...     &gt;&gt;&gt; from http.client import HTTPException
...     &gt;&gt;&gt; raise HTTPException() #doctest: +IGNORE_EXCEPTION_DETAIL
...     Traceback (most recent call last):
...     foo.bar.HTTPException
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
TestResults(failed=0, attempted=2)

Note that a trailing colon doesn't matter either:

&gt;&gt;&gt; def f(x):
...     r'''
...     &gt;&gt;&gt; from http.client import HTTPException
...     &gt;&gt;&gt; raise HTTPException() #doctest: +IGNORE_EXCEPTION_DETAIL
...     Traceback (most recent call last):
...     foo.bar.HTTPException:
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
TestResults(failed=0, attempted=2)

If an exception is raised but not expected, then it is reported as an
unexpected exception:

&gt;&gt;&gt; def f(x):
...     r'''
...     &gt;&gt;&gt; 1//0
...     0
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 3, in f
Failed example:
    1//0
Exception raised:
    Traceback (most recent call last):
    ...
    ZeroDivisionError: integer division or modulo by zero
TestResults(failed=1, attempted=1)
</pre> 
</div>
</div>
<a id="a73e15e4f95afc8b2f8afec2a54606128"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a73e15e4f95afc8b2f8afec2a54606128">&#9670;&nbsp;</a></span>option_directives()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def test.test_doctest.test_doctest.test_DocTestRunner.option_directives </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Tests of `DocTestRunner`'s option directive mechanism.

Option directives can be used to turn option flags on or off for a
single example.  To turn an option on for an example, follow that
example with a comment of the form ``# doctest: +OPTION``:

&gt;&gt;&gt; def f(x): r'''
...     &gt;&gt;&gt; print(list(range(10)))      # should fail: no ellipsis
...     [0, 1, ..., 9]
...
...     &gt;&gt;&gt; print(list(range(10)))      # doctest: +ELLIPSIS
...     [0, 1, ..., 9]
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 2, in f
Failed example:
    print(list(range(10)))      # should fail: no ellipsis
Expected:
    [0, 1, ..., 9]
Got:
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
TestResults(failed=1, attempted=2)

To turn an option off for an example, follow that example with a
comment of the form ``# doctest: -OPTION``:

&gt;&gt;&gt; def f(x): r'''
...     &gt;&gt;&gt; print(list(range(10)))
...     [0, 1, ..., 9]
...
...     &gt;&gt;&gt; # should fail: no ellipsis
...     &gt;&gt;&gt; print(list(range(10)))      # doctest: -ELLIPSIS
...     [0, 1, ..., 9]
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False,
...                       optionflags=doctest.ELLIPSIS).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 6, in f
Failed example:
    print(list(range(10)))      # doctest: -ELLIPSIS
Expected:
    [0, 1, ..., 9]
Got:
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
TestResults(failed=1, attempted=2)

Option directives affect only the example that they appear with; they
do not change the options for surrounding examples:

&gt;&gt;&gt; def f(x): r'''
...     &gt;&gt;&gt; print(list(range(10)))      # Should fail: no ellipsis
...     [0, 1, ..., 9]
...
...     &gt;&gt;&gt; print(list(range(10)))      # doctest: +ELLIPSIS
...     [0, 1, ..., 9]
...
...     &gt;&gt;&gt; print(list(range(10)))      # Should fail: no ellipsis
...     [0, 1, ..., 9]
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 2, in f
Failed example:
    print(list(range(10)))      # Should fail: no ellipsis
Expected:
    [0, 1, ..., 9]
Got:
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
**********************************************************************
File ..., line 8, in f
Failed example:
    print(list(range(10)))      # Should fail: no ellipsis
Expected:
    [0, 1, ..., 9]
Got:
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
TestResults(failed=2, attempted=3)

Multiple options may be modified by a single option directive.  They
may be separated by whitespace, commas, or both:

&gt;&gt;&gt; def f(x): r'''
...     &gt;&gt;&gt; print(list(range(10)))      # Should fail
...     [0, 1,  ...,   9]
...     &gt;&gt;&gt; print(list(range(10)))      # Should succeed
...     ... # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE
...     [0, 1,  ...,   9]
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 2, in f
Failed example:
    print(list(range(10)))      # Should fail
Expected:
    [0, 1,  ...,   9]
Got:
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
TestResults(failed=1, attempted=2)

&gt;&gt;&gt; def f(x): r'''
...     &gt;&gt;&gt; print(list(range(10)))      # Should fail
...     [0, 1,  ...,   9]
...     &gt;&gt;&gt; print(list(range(10)))      # Should succeed
...     ... # doctest: +ELLIPSIS,+NORMALIZE_WHITESPACE
...     [0, 1,  ...,   9]
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 2, in f
Failed example:
    print(list(range(10)))      # Should fail
Expected:
    [0, 1,  ...,   9]
Got:
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
TestResults(failed=1, attempted=2)

&gt;&gt;&gt; def f(x): r'''
...     &gt;&gt;&gt; print(list(range(10)))      # Should fail
...     [0, 1,  ...,   9]
...     &gt;&gt;&gt; print(list(range(10)))      # Should succeed
...     ... # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE
...     [0, 1,  ...,   9]
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 2, in f
Failed example:
    print(list(range(10)))      # Should fail
Expected:
    [0, 1,  ...,   9]
Got:
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
TestResults(failed=1, attempted=2)

The option directive may be put on the line following the source, as
long as a continuation prompt is used:

&gt;&gt;&gt; def f(x): r'''
...     &gt;&gt;&gt; print(list(range(10)))
...     ... # doctest: +ELLIPSIS
...     [0, 1, ..., 9]
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
TestResults(failed=0, attempted=1)

For examples with multi-line source, the option directive may appear
at the end of any line:

&gt;&gt;&gt; def f(x): r'''
...     &gt;&gt;&gt; for x in range(10): # doctest: +ELLIPSIS
...     ...     print(' ', x, end='', sep='')
...      0 1 2 ... 9
...
...     &gt;&gt;&gt; for x in range(10):
...     ...     print(' ', x, end='', sep='') # doctest: +ELLIPSIS
...      0 1 2 ... 9
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
TestResults(failed=0, attempted=2)

If more than one line of an example with multi-line source has an
option directive, then they are combined:

&gt;&gt;&gt; def f(x): r'''
...     Should fail (option directive not on the last line):
...         &gt;&gt;&gt; for x in range(10): # doctest: +ELLIPSIS
...         ...     print(x, end=' ') # doctest: +NORMALIZE_WHITESPACE
...         0  1    2...9
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
TestResults(failed=0, attempted=1)

It is an error to have a comment of the form ``# doctest:`` that is
*not* followed by words of the form ``+OPTION`` or ``-OPTION``, where
``OPTION`` is an option that has been registered with
`register_option`:

&gt;&gt;&gt; # Error: Option not registered
&gt;&gt;&gt; s = '&gt;&gt;&gt; print(12)  #doctest: +BADOPTION'
&gt;&gt;&gt; test = doctest.DocTestParser().get_doctest(s, {}, 's', 's.py', 0)
Traceback (most recent call last):
ValueError: line 1 of the doctest for s has an invalid option: '+BADOPTION'

&gt;&gt;&gt; # Error: No + or - prefix
&gt;&gt;&gt; s = '&gt;&gt;&gt; print(12)  #doctest: ELLIPSIS'
&gt;&gt;&gt; test = doctest.DocTestParser().get_doctest(s, {}, 's', 's.py', 0)
Traceback (most recent call last):
ValueError: line 1 of the doctest for s has an invalid option: 'ELLIPSIS'

It is an error to use an option directive on a line that contains no
source:

&gt;&gt;&gt; s = '&gt;&gt;&gt; # doctest: +ELLIPSIS'
&gt;&gt;&gt; test = doctest.DocTestParser().get_doctest(s, {}, 's', 's.py', 0)
Traceback (most recent call last):
ValueError: line 0 of the doctest for s has an option directive on a line with no example: '# doctest: +ELLIPSIS'
</pre> 
</div>
</div>
<a id="a02b31e6aacfb7e1b5bc7083392f3d440"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a02b31e6aacfb7e1b5bc7083392f3d440">&#9670;&nbsp;</a></span>optionflags()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def test.test_doctest.test_doctest.test_DocTestRunner.optionflags </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Tests of `DocTestRunner`'s option flag handling.

Several option flags can be used to customize the behavior of the test
runner.  These are defined as module constants in doctest, and passed
to the DocTestRunner constructor (multiple constants should be ORed
together).

The DONT_ACCEPT_TRUE_FOR_1 flag disables matches between True/False
and 1/0:

&gt;&gt;&gt; def f(x):
...     '&gt;&gt;&gt; True\n1\n'

&gt;&gt;&gt; # Without the flag:
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
TestResults(failed=0, attempted=1)

&gt;&gt;&gt; # With the flag:
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; flags = doctest.DONT_ACCEPT_TRUE_FOR_1
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False, optionflags=flags).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 2, in f
Failed example:
    True
Expected:
    1
Got:
    True
TestResults(failed=1, attempted=1)

The DONT_ACCEPT_BLANKLINE flag disables the match between blank lines
and the '&lt;BLANKLINE&gt;' marker:

&gt;&gt;&gt; def f(x):
...     '&gt;&gt;&gt; print("a\\n\\nb")\na\n&lt;BLANKLINE&gt;\nb\n'

&gt;&gt;&gt; # Without the flag:
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
TestResults(failed=0, attempted=1)

&gt;&gt;&gt; # With the flag:
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; flags = doctest.DONT_ACCEPT_BLANKLINE
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False, optionflags=flags).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 2, in f
Failed example:
    print("a\n\nb")
Expected:
    a
    &lt;BLANKLINE&gt;
    b
Got:
    a
&lt;BLANKLINE&gt;
    b
TestResults(failed=1, attempted=1)

The NORMALIZE_WHITESPACE flag causes all sequences of whitespace to be
treated as equal:

&gt;&gt;&gt; def f(x):
...     '&gt;&gt;&gt; print(1, 2, 3)\n  1   2\n 3'

&gt;&gt;&gt; # Without the flag:
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 2, in f
Failed example:
    print(1, 2, 3)
Expected:
      1   2
     3
Got:
    1 2 3
TestResults(failed=1, attempted=1)

&gt;&gt;&gt; # With the flag:
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; flags = doctest.NORMALIZE_WHITESPACE
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False, optionflags=flags).run(test)
TestResults(failed=0, attempted=1)

An example from the docs:
&gt;&gt;&gt; print(list(range(20))) #doctest: +NORMALIZE_WHITESPACE
[0,   1,  2,  3,  4,  5,  6,  7,  8,  9,
10,  11, 12, 13, 14, 15, 16, 17, 18, 19]

The ELLIPSIS flag causes ellipsis marker ("...") in the expected
output to match any substring in the actual output:

&gt;&gt;&gt; def f(x):
...     '&gt;&gt;&gt; print(list(range(15)))\n[0, 1, 2, ..., 14]\n'

&gt;&gt;&gt; # Without the flag:
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 2, in f
Failed example:
    print(list(range(15)))
Expected:
    [0, 1, 2, ..., 14]
Got:
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
TestResults(failed=1, attempted=1)

&gt;&gt;&gt; # With the flag:
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; flags = doctest.ELLIPSIS
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False, optionflags=flags).run(test)
TestResults(failed=0, attempted=1)

... also matches nothing:

&gt;&gt;&gt; if 1:
...     for i in range(100):
...         print(i**2, end=' ') #doctest: +ELLIPSIS
...     print('!')
0 1...4...9 16 ... 36 49 64 ... 9801 !

... can be surprising; e.g., this test passes:

&gt;&gt;&gt; if 1:  #doctest: +ELLIPSIS
...     for i in range(20):
...         print(i, end=' ')
...     print(20)
0 1 2 ...1...2...0

Examples from the docs:

&gt;&gt;&gt; print(list(range(20))) # doctest:+ELLIPSIS
[0, 1, ..., 18, 19]

&gt;&gt;&gt; print(list(range(20))) # doctest: +ELLIPSIS
...                 # doctest: +NORMALIZE_WHITESPACE
[0,    1, ...,   18,    19]

The SKIP flag causes an example to be skipped entirely.  I.e., the
example is not run.  It can be useful in contexts where doctest
examples serve as both documentation and test cases, and an example
should be included for documentation purposes, but should not be
checked (e.g., because its output is random, or depends on resources
which would be unavailable.)  The SKIP flag can also be used for
'commenting out' broken examples.

&gt;&gt;&gt; import unavailable_resource           # doctest: +SKIP
&gt;&gt;&gt; unavailable_resource.do_something()   # doctest: +SKIP
&gt;&gt;&gt; unavailable_resource.blow_up()        # doctest: +SKIP
Traceback (most recent call last):
    ...
UncheckedBlowUpError:  Nobody checks me.

&gt;&gt;&gt; import random
&gt;&gt;&gt; print(random.random()) # doctest: +SKIP
0.721216923889

The REPORT_UDIFF flag causes failures that involve multi-line expected
and actual outputs to be displayed using a unified diff:

&gt;&gt;&gt; def f(x):
...     r'''
...     &gt;&gt;&gt; print('\n'.join('abcdefg'))
...     a
...     B
...     c
...     d
...     f
...     g
...     h
...     '''

&gt;&gt;&gt; # Without the flag:
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 3, in f
Failed example:
    print('\n'.join('abcdefg'))
Expected:
    a
    B
    c
    d
    f
    g
    h
Got:
    a
    b
    c
    d
    e
    f
    g
TestResults(failed=1, attempted=1)

&gt;&gt;&gt; # With the flag:
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; flags = doctest.REPORT_UDIFF
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False, optionflags=flags).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 3, in f
Failed example:
    print('\n'.join('abcdefg'))
Differences (unified diff with -expected +actual):
    @@ -1,7 +1,7 @@
     a
    -B
    +b
     c
     d
    +e
     f
     g
    -h
TestResults(failed=1, attempted=1)

The REPORT_CDIFF flag causes failures that involve multi-line expected
and actual outputs to be displayed using a context diff:

&gt;&gt;&gt; # Reuse f() from the REPORT_UDIFF example, above.
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; flags = doctest.REPORT_CDIFF
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False, optionflags=flags).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 3, in f
Failed example:
    print('\n'.join('abcdefg'))
Differences (context diff with expected followed by actual):
    ***************
    *** 1,7 ****
      a
    ! B
      c
      d
      f
      g
    - h
    --- 1,7 ----
      a
    ! b
      c
      d
    + e
      f
      g
TestResults(failed=1, attempted=1)


The REPORT_NDIFF flag causes failures to use the difflib.Differ algorithm
used by the popular ndiff.py utility.  This does intraline difference
marking, as well as interline differences.

&gt;&gt;&gt; def f(x):
...     r'''
...     &gt;&gt;&gt; print("a b  c d e f g h i   j k l m")
...     a b c d e f g h i j k 1 m
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; flags = doctest.REPORT_NDIFF
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False, optionflags=flags).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 3, in f
Failed example:
    print("a b  c d e f g h i   j k l m")
Differences (ndiff with -expected +actual):
    - a b c d e f g h i j k 1 m
    ?                       ^
    + a b  c d e f g h i   j k l m
    ?     +              ++    ^
TestResults(failed=1, attempted=1)

The REPORT_ONLY_FIRST_FAILURE suppresses result output after the first
failing example:

&gt;&gt;&gt; def f(x):
...     r'''
...     &gt;&gt;&gt; print(1) # first success
...     1
...     &gt;&gt;&gt; print(2) # first failure
...     200
...     &gt;&gt;&gt; print(3) # second failure
...     300
...     &gt;&gt;&gt; print(4) # second success
...     4
...     &gt;&gt;&gt; print(5) # third failure
...     500
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; flags = doctest.REPORT_ONLY_FIRST_FAILURE
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False, optionflags=flags).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 5, in f
Failed example:
    print(2) # first failure
Expected:
    200
Got:
    2
TestResults(failed=3, attempted=5)

However, output from `report_start` is not suppressed:

&gt;&gt;&gt; doctest.DocTestRunner(verbose=True, optionflags=flags).run(test)
... # doctest: +ELLIPSIS
Trying:
    print(1) # first success
Expecting:
    1
ok
Trying:
    print(2) # first failure
Expecting:
    200
**********************************************************************
File ..., line 5, in f
Failed example:
    print(2) # first failure
Expected:
    200
Got:
    2
TestResults(failed=3, attempted=5)

The FAIL_FAST flag causes the runner to exit after the first failing example,
so subsequent examples are not even attempted:

&gt;&gt;&gt; flags = doctest.FAIL_FAST
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False, optionflags=flags).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 5, in f
Failed example:
    print(2) # first failure
Expected:
    200
Got:
    2
TestResults(failed=1, attempted=2)

Specifying both FAIL_FAST and REPORT_ONLY_FIRST_FAILURE is equivalent to
FAIL_FAST only:

&gt;&gt;&gt; flags = doctest.FAIL_FAST | doctest.REPORT_ONLY_FIRST_FAILURE
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False, optionflags=flags).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 5, in f
Failed example:
    print(2) # first failure
Expected:
    200
Got:
    2
TestResults(failed=1, attempted=2)

For the purposes of both REPORT_ONLY_FIRST_FAILURE and FAIL_FAST, unexpected
exceptions count as failures:

&gt;&gt;&gt; def f(x):
...     r'''
...     &gt;&gt;&gt; print(1) # first success
...     1
...     &gt;&gt;&gt; raise ValueError(2) # first failure
...     200
...     &gt;&gt;&gt; print(3) # second failure
...     300
...     &gt;&gt;&gt; print(4) # second success
...     4
...     &gt;&gt;&gt; print(5) # third failure
...     500
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]
&gt;&gt;&gt; flags = doctest.REPORT_ONLY_FIRST_FAILURE
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False, optionflags=flags).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 5, in f
Failed example:
    raise ValueError(2) # first failure
Exception raised:
    ...
    ValueError: 2
TestResults(failed=3, attempted=5)
&gt;&gt;&gt; flags = doctest.FAIL_FAST
&gt;&gt;&gt; doctest.DocTestRunner(verbose=False, optionflags=flags).run(test)
... # doctest: +ELLIPSIS
**********************************************************************
File ..., line 5, in f
Failed example:
    raise ValueError(2) # first failure
Exception raised:
    ...
    ValueError: 2
TestResults(failed=1, attempted=2)

New option flags can also be registered, via register_optionflag().  Here
we reach into doctest's internals a bit.

&gt;&gt;&gt; unlikely = "UNLIKELY_OPTION_NAME"
&gt;&gt;&gt; unlikely in doctest.OPTIONFLAGS_BY_NAME
False
&gt;&gt;&gt; new_flag_value = doctest.register_optionflag(unlikely)
&gt;&gt;&gt; unlikely in doctest.OPTIONFLAGS_BY_NAME
True

Before 2.4.4/2.5, registering a name more than once erroneously created
more than one flag value.  Here we verify that's fixed:

&gt;&gt;&gt; redundant_flag_value = doctest.register_optionflag(unlikely)
&gt;&gt;&gt; redundant_flag_value == new_flag_value
True

Clean up.
&gt;&gt;&gt; del doctest.OPTIONFLAGS_BY_NAME[unlikely]</pre> 
</div>
</div>
<a id="a6a1a17315e6966427dbbba5cecafa9cb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6a1a17315e6966427dbbba5cecafa9cb">&#9670;&nbsp;</a></span>verbose_flag()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def test.test_doctest.test_doctest.test_DocTestRunner.verbose_flag </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">The `verbose` flag makes the test runner generate more detailed
output:

&gt;&gt;&gt; def f(x):
...     '''
...     &gt;&gt;&gt; x = 12
...     &gt;&gt;&gt; print(x)
...     12
...     &gt;&gt;&gt; x//2
...     6
...     '''
&gt;&gt;&gt; test = doctest.DocTestFinder().find(f)[0]

&gt;&gt;&gt; doctest.DocTestRunner(verbose=True).run(test)
Trying:
    x = 12
Expecting nothing
ok
Trying:
    print(x)
Expecting:
    12
ok
Trying:
    x//2
Expecting:
    6
ok
TestResults(failed=0, attempted=3)

If the `verbose` flag is unspecified, then the output will be verbose
iff `-v` appears in sys.argv:

&gt;&gt;&gt; # Save the real sys.argv list.
&gt;&gt;&gt; old_argv = sys.argv

&gt;&gt;&gt; # If -v does not appear in sys.argv, then output isn't verbose.
&gt;&gt;&gt; sys.argv = ['test']
&gt;&gt;&gt; doctest.DocTestRunner().run(test)
TestResults(failed=0, attempted=3)

&gt;&gt;&gt; # If -v does appear in sys.argv, then output is verbose.
&gt;&gt;&gt; sys.argv = ['test', '-v']
&gt;&gt;&gt; doctest.DocTestRunner().run(test)
Trying:
    x = 12
Expecting nothing
ok
Trying:
    print(x)
Expecting:
    12
ok
Trying:
    x//2
Expecting:
    6
ok
TestResults(failed=0, attempted=3)

&gt;&gt;&gt; # Restore sys.argv
&gt;&gt;&gt; sys.argv = old_argv

In the remaining examples, the test runner's verbosity will be
explicitly set, to ensure that the test behavior is consistent.
</pre> 
</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>UI-UX/SFML/lib/python3.12/test/test_doctest/test_doctest.py</li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
